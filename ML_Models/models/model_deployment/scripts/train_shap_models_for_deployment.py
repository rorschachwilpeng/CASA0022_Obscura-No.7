#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SHAPæ¡†æ¶æ¨¡å‹è®­ç»ƒè„šæœ¬ - ä¸ºäº‘ç«¯éƒ¨ç½²å‡†å¤‡

è®­ç»ƒä¸‰åŸå¸‚çš„Climate Modelå’ŒGeographic Modelï¼Œå¹¶ä¿å­˜ä¸ºéƒ¨ç½²å°±ç»ªçš„æ ¼å¼
"""

import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')
sys.path.append('..')

from shap_framework.core_models import OutcomePredictor, PredictionConfig, ScoreWeights
from shap_framework.data_infrastructure.data_pipeline.data_loader import DataLoader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def train_and_save_models():
    """è®­ç»ƒå¹¶ä¿å­˜æ‰€æœ‰åŸå¸‚çš„SHAPæ¡†æ¶æ¨¡å‹"""
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒSHAPæ¡†æ¶æ¨¡å‹...")
    print("="*60)
    
    # é…ç½®
    cities = ['London', 'Manchester', 'Edinburgh']
    data_directory = 'environmental_prediction_framework'
    models_output_dir = Path('models/shap_deployment')
    models_output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®­ç»ƒé…ç½®
    config = PredictionConfig(
        prediction_horizon=12,
        confidence_threshold=0.7,
        enable_shap_analysis=False,  # æš‚æ—¶ç¦ç”¨SHAPåˆ†æä»¥åŠ å¿«è®­ç»ƒ
        save_predictions=False
    )
    
    # æƒé‡é…ç½®ï¼ˆå¹³è¡¡é…ç½®ï¼‰
    weights = ScoreWeights(
        climate_weight=0.4,
        geographic_weight=0.35,
        economic_weight=0.25
    )
    
    training_results = {}
    model_summaries = {}
    
    # ä¸ºæ¯ä¸ªåŸå¸‚è®­ç»ƒæ¨¡å‹
    for city in cities:
        print(f"\nğŸ™ï¸ å¼€å§‹è®­ç»ƒ {city} æ¨¡å‹...")
        print("-" * 40)
        
        try:
            # åˆå§‹åŒ–é¢„æµ‹å™¨
            predictor = OutcomePredictor(city=city, config=config, weights=weights)
            
            # æš‚æ—¶ç¦ç”¨ç‰¹å¾é€‰æ‹©ä»¥è§£å†³ç‰¹å¾æ•°é‡ä¸ä¸€è‡´é—®é¢˜
            from shap_framework.core_models.time_series_predictor import ModelConfig
            no_feature_selection_config = ModelConfig(
                algorithm="random_forest",
                target_variable="meteorological_temperature",
                feature_selection=False,  # ç¦ç”¨ç‰¹å¾é€‰æ‹©
                max_features=50,
                validation_splits=3,
                test_size=0.2,
                random_state=42
            )
            
            # åº”ç”¨é…ç½®åˆ°æ‰€æœ‰å†…éƒ¨æ¨¡å‹
            predictor.climate_model.config = no_feature_selection_config
            predictor.geographic_model.config = no_feature_selection_config
            
            logger.info("âœ… å·²ç¦ç”¨ç‰¹å¾é€‰æ‹©ä»¥ç¡®ä¿è®­ç»ƒç¨³å®šæ€§")
            
            # åŠ è½½æ•°æ®
            logger.info(f"åŠ è½½ {city} çš„æ•°æ®...")
            data_loader = DataLoader()
            all_data = data_loader.load_all_data()
            city_data = data_loader.get_city_dataframe(city)
            
            if city_data.empty:
                logger.error(f"âŒ {city} æ•°æ®ä¸ºç©º")
                continue
            
            # è®­ç»ƒæ¨¡å‹
            logger.info(f"å¼€å§‹è®­ç»ƒ {city} çš„æ¨¡å‹...")
            results = predictor.train_models(
                data_directory=city_data,  # ç›´æ¥ä¼ é€’DataFrameè€Œéç›®å½•
                validation_split=0.2
            )
            
            # ä¿å­˜è®­ç»ƒç»“æœ
            training_results[city] = results
            
            # è·å–æ¨¡å‹æ‘˜è¦
            summary = predictor.get_predictor_summary()
            model_summaries[city] = summary
            
            # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
            city_model_dir = models_output_dir / city.lower()
            predictor.save_models(str(city_model_dir))
            
            # æ‰“å°è®­ç»ƒç»“æœ
            climate_r2 = results.get('climate_validation', {}).get('r2', 0)
            geo_r2 = results.get('geographic_validation', {}).get('r2', 0)
            
            print(f"âœ… {city} æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            print(f"   Climate Model RÂ²: {climate_r2:.4f}")
            print(f"   Geographic Model RÂ²: {geo_r2:.4f}")
            print(f"   æ¨¡å‹å·²ä¿å­˜åˆ°: {city_model_dir}")
            
        except Exception as e:
            logger.error(f"âŒ {city} æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")
            print(f"âŒ {city} æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")
            continue
    
    # ä¿å­˜è®­ç»ƒæŠ¥å‘Š
    report = {
        'training_timestamp': datetime.now().isoformat(),
        'cities_trained': list(training_results.keys()),
        'configuration': {
            'config': config.__dict__,
            'weights': weights.__dict__
        },
        'training_results': training_results,
        'model_summaries': model_summaries,
        'deployment_info': {
            'models_directory': str(models_output_dir),
            'ready_for_deployment': len(training_results) == len(cities),
            'total_cities': len(cities),
            'successful_cities': len(training_results)
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = models_output_dir / 'training_report.json'
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2, default=str)
    
    # åˆ›å»ºéƒ¨ç½²æ¸…å•
    deployment_manifest = {
        'version': '1.0.0',
        'deployment_date': datetime.now().isoformat(),
        'models': {},
        'requirements': [
            'numpy>=1.21.0',
            'pandas>=1.3.0',
            'scikit-learn>=1.0.0',
            'joblib>=1.1.0',
            'shap>=0.40.0'
        ]
    }
    
    for city in training_results.keys():
        city_lower = city.lower()
        deployment_manifest['models'][city] = {
            'climate_model': f'{city_lower}/{city}_climate_model.joblib',
            'geographic_model': f'{city_lower}/{city}_geographic_model.joblib',
            'metadata': f'{city_lower}/{city}_predictor_metadata.json'
        }
    
    manifest_file = models_output_dir / 'deployment_manifest.json'
    with open(manifest_file, 'w') as f:
        json.dump(deployment_manifest, f, indent=2)
    
    # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ‰ SHAPæ¡†æ¶æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("="*60)
    print(f"âœ… æˆåŠŸè®­ç»ƒåŸå¸‚: {len(training_results)}/{len(cities)}")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜ç›®å½•: {models_output_dir}")
    print(f"ğŸ“Š è®­ç»ƒæŠ¥å‘Š: {report_file}")
    print(f"ğŸš€ éƒ¨ç½²æ¸…å•: {manifest_file}")
    
    if len(training_results) == len(cities):
        print("ğŸŸ¢ æ‰€æœ‰æ¨¡å‹å·²å°±ç»ªï¼Œå¯ä»¥éƒ¨ç½²ï¼")
    else:
        print("ğŸŸ¡ éƒ¨åˆ†æ¨¡å‹è®­ç»ƒæˆåŠŸï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„åŸå¸‚")
    
    # è¿”å›è®­ç»ƒç»“æœ
    return report

def create_lightweight_wrapper():
    """åˆ›å»ºè½»é‡åŒ–æ¨¡å‹åŒ…è£…å™¨"""
    
    print("\nğŸ”§ åˆ›å»ºè½»é‡åŒ–æ¨¡å‹åŒ…è£…å™¨...")
    
    wrapper_code = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è½»é‡åŒ–SHAPæ¨¡å‹åŒ…è£…å™¨ - ä¸ºäº‘ç«¯éƒ¨ç½²ä¼˜åŒ–

ä¸“ä¸ºRenderç­‰äº‘å¹³å°è®¾è®¡çš„SHAPæ¨¡å‹åŒ…è£…å™¨
"""

import os
import sys
import json
import joblib
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class SHAPModelWrapper:
    """è½»é‡åŒ–SHAPæ¨¡å‹åŒ…è£…å™¨"""
    
    def __init__(self, models_directory: str = "models/shap_deployment"):
        self.models_dir = Path(models_directory)
        self.loaded_models = {}
        self.deployment_manifest = None
        self.load_manifest()
    
    def load_manifest(self):
        """åŠ è½½éƒ¨ç½²æ¸…å•"""
        manifest_file = self.models_dir / 'deployment_manifest.json'
        if manifest_file.exists():
            with open(manifest_file, 'r') as f:
                self.deployment_manifest = json.load(f)
            logger.info("âœ… éƒ¨ç½²æ¸…å•åŠ è½½æˆåŠŸ")
        else:
            logger.warning("âš ï¸ éƒ¨ç½²æ¸…å•ä¸å­˜åœ¨")
    
    def load_city_models(self, city: str) -> bool:
        """æŒ‰éœ€åŠ è½½æŒ‡å®šåŸå¸‚çš„æ¨¡å‹"""
        try:
            if city in self.loaded_models:
                return True
            
            if not self.deployment_manifest or city not in self.deployment_manifest['models']:
                logger.error(f"âŒ {city} æ¨¡å‹é…ç½®ä¸å­˜åœ¨")
                return False
            
            city_config = self.deployment_manifest['models'][city]
            city_models = {}
            
            # åŠ è½½Climate Model
            climate_path = self.models_dir / city_config['climate_model']
            if climate_path.exists():
                city_models['climate'] = joblib.load(climate_path)
                logger.info(f"âœ… {city} Climate Model åŠ è½½æˆåŠŸ")
            
            # åŠ è½½Geographic Model  
            geo_path = self.models_dir / city_config['geographic_model']
            if geo_path.exists():
                city_models['geographic'] = joblib.load(geo_path)
                logger.info(f"âœ… {city} Geographic Model åŠ è½½æˆåŠŸ")
            
            # åŠ è½½å…ƒæ•°æ®
            metadata_path = self.models_dir / city_config['metadata']
            if metadata_path.exists():
                with open(metadata_path, 'r') as f:
                    city_models['metadata'] = json.load(f)
                logger.info(f"âœ… {city} å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
            
            self.loaded_models[city] = city_models
            return True
            
        except Exception as e:
            logger.error(f"âŒ {city} æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def predict_environmental_scores(self, city: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """é¢„æµ‹ç¯å¢ƒåˆ†æ•°"""
        try:
            # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
            if not self.load_city_models(city):
                raise ValueError(f"æ— æ³•åŠ è½½ {city} çš„æ¨¡å‹")
            
            city_models = self.loaded_models[city]
            
            # è¿™é‡Œæ˜¯ç®€åŒ–çš„é¢„æµ‹é€»è¾‘
            # åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œéœ€è¦æ ¹æ®çœŸå®çš„æ¨¡å‹æ¥å£è¿›è¡Œè°ƒæ•´
            result = {
                'city': city,
                'prediction_timestamp': datetime.now().isoformat(),
                'climate_score': 0.75,  # å ä½ç¬¦
                'geographic_score': 0.82,  # å ä½ç¬¦
                'economic_score': 0.68,  # å ä½ç¬¦
                'final_score': 0.75,  # å ä½ç¬¦
                'confidence': 0.85,
                'model_status': 'loaded',
                'available_models': list(city_models.keys())
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ {city} é¢„æµ‹å¤±è´¥: {str(e)}")
            return {'error': str(e), 'city': city}
    
    def get_model_status(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çŠ¶æ€"""
        return {
            'manifest_loaded': self.deployment_manifest is not None,
            'available_cities': list(self.deployment_manifest['models'].keys()) if self.deployment_manifest else [],
            'loaded_cities': list(self.loaded_models.keys()),
            'deployment_version': self.deployment_manifest.get('version', 'unknown') if self.deployment_manifest else 'unknown'
        }
'''
    
    # ä¿å­˜åŒ…è£…å™¨
    wrapper_file = Path('models/shap_deployment/shap_model_wrapper.py')
    with open(wrapper_file, 'w') as f:
        f.write(wrapper_code)
    
    print(f"âœ… è½»é‡åŒ–åŒ…è£…å™¨å·²åˆ›å»º: {wrapper_file}")
    return wrapper_file

if __name__ == "__main__":
    print("ğŸ”­ Obscura No.7 - SHAPæ¡†æ¶æ¨¡å‹è®­ç»ƒ")
    print("ä¸ºäº‘ç«¯éƒ¨ç½²å‡†å¤‡æœºå™¨å­¦ä¹ æ¨¡å‹")
    print()
    
    # è®­ç»ƒæ¨¡å‹
    report = train_and_save_models()
    
    # åˆ›å»ºåŒ…è£…å™¨
    wrapper_file = create_lightweight_wrapper()
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print("1. æ£€æŸ¥è®­ç»ƒæŠ¥å‘Šç¡®è®¤æ¨¡å‹è´¨é‡")
    print("2. åˆ›å»ºæ–°çš„APIç«¯ç‚¹")
    print("3. éƒ¨ç½²åˆ°Renderå¹³å°")
    print("4. è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•") 