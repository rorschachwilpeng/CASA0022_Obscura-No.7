#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Geographicæ¨¡å‹è®­ç»ƒå™¨
ä½¿ç”¨LSTMè®­ç»ƒGeographicé¢„æµ‹æ¨¡å‹
"""

import os
import pickle
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import logging
from typing import Dict, Any, Tuple
from tqdm import tqdm

# TensorFlow/Keras imports
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

from .training_config import TrainingConfig

class GeographicTrainer:
    """Geographicæ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.model = None
        self.scaler = StandardScaler()
        self.logger = self._setup_logger()
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def load_data(self) -> Tuple[np.ndarray, np.ndarray]:
        """åŠ è½½è®­ç»ƒæ•°æ®"""
        self.logger.info(f"ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®: {self.config.data_cache_path}")
        
        try:
            with open(self.config.data_cache_path, 'rb') as f:
                data = pickle.load(f)
            
            X = data['X']
            y_geographic = data['y_geographic']
            
            self.logger.info(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: X={X.shape}, y_geographic={y_geographic.shape}")
            return X, y_geographic
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def prepare_data(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        self.logger.info("ğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # æ•°æ®åˆ†å‰²
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=self.config.test_size, random_state=self.config.random_state
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=self.config.val_size/(1-self.config.test_size), 
            random_state=self.config.random_state
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)
        X_test_scaled = self.scaler.transform(X_test)
        
        # é‡å¡‘æ•°æ®ä¸ºLSTMæ ¼å¼ (samples, timesteps, features)
        # å¯¹äºLSTMï¼Œæˆ‘ä»¬å°†æ¯ä¸ªæ ·æœ¬ä½œä¸ºä¸€ä¸ªæ—¶é—´æ­¥
        X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])
        X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], 1, X_val_scaled.shape[1])
        X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])
        
        self.logger.info(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ:")
        self.logger.info(f"   è®­ç»ƒé›†: {X_train_reshaped.shape}")
        self.logger.info(f"   éªŒè¯é›†: {X_val_reshaped.shape}")
        self.logger.info(f"   æµ‹è¯•é›†: {X_test_reshaped.shape}")
        
        return X_train_reshaped, X_val_reshaped, X_test_reshaped, y_train, y_val, y_test
    
    def build_model(self, input_shape: Tuple[int, int]) -> Sequential:
        """æ„å»ºLSTMæ¨¡å‹"""
        self.logger.info("ğŸ—ï¸ æ„å»ºLSTM Geographicæ¨¡å‹...")
        
        model = Sequential([
            LSTM(
                units=self.config.geographic_model_params['units'],
                dropout=self.config.geographic_model_params['dropout'],
                recurrent_dropout=self.config.geographic_model_params['recurrent_dropout'],
                return_sequences=self.config.geographic_model_params['return_sequences'],
                input_shape=input_shape
            ),
            Dense(32, activation='relu'),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='linear')
        ])
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=Adam(learning_rate=self.config.learning_rate),
            loss='mse',
            metrics=['mae']
        )
        
        self.logger.info("âœ… LSTMæ¨¡å‹æ„å»ºå®Œæˆ")
        return model
    
    def train_model(self, X_train: np.ndarray, y_train: np.ndarray, 
                   X_val: np.ndarray, y_val: np.ndarray) -> Sequential:
        """è®­ç»ƒLSTMæ¨¡å‹"""
        self.logger.info("ğŸ§  å¼€å§‹è®­ç»ƒLSTM Geographicæ¨¡å‹...")
        
        # æ„å»ºæ¨¡å‹
        self.model = self.build_model((X_train.shape[1], X_train.shape[2]))
        
        # è®¾ç½®å›è°ƒå‡½æ•°
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=self.config.early_stopping_patience,
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            )
        ]
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=self.config.max_epochs,
            batch_size=self.config.batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        self.logger.info("âœ… Geographicæ¨¡å‹è®­ç»ƒå®Œæˆ")
        return self.model
    
    def evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        self.logger.info("ğŸ“Š è¯„ä¼°Geographicæ¨¡å‹æ€§èƒ½...")
        
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train_modelæ–¹æ³•")
        
        # é¢„æµ‹
        y_pred = self.model.predict(X_test).flatten()
        
        # è®¡ç®—æŒ‡æ ‡
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mse)
        
        metrics = {
            'mse': mse,
            'mae': mae,
            'r2': r2,
            'rmse': rmse
        }
        
        self.logger.info("ğŸ“ˆ Geographicæ¨¡å‹æ€§èƒ½æŒ‡æ ‡:")
        for metric, value in metrics.items():
            self.logger.info(f"   {metric}: {value:.4f}")
        
        return metrics
    
    def save_model(self, model_path: str, scaler_path: str):
        """ä¿å­˜æ¨¡å‹å’Œç¼©æ”¾å™¨"""
        self.logger.info(f"ğŸ’¾ ä¿å­˜Geographicæ¨¡å‹åˆ°: {model_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹
        self.model.save(model_path)
        
        # ä¿å­˜ç¼©æ”¾å™¨
        joblib.dump(self.scaler, scaler_path)
        
        self.logger.info("âœ… Geographicæ¨¡å‹ä¿å­˜å®Œæˆ")
    
    def train_and_evaluate(self) -> Dict[str, Any]:
        """å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹Geographicæ¨¡å‹è®­ç»ƒæµç¨‹...")
        
        try:
            # 1. åŠ è½½æ•°æ®
            X, y = self.load_data()
            
            # 2. å‡†å¤‡æ•°æ®
            X_train, X_val, X_test, y_train, y_val, y_test = self.prepare_data(X, y)
            
            # 3. è®­ç»ƒæ¨¡å‹
            self.train_model(X_train, y_train, X_val, y_val)
            
            # 4. è¯„ä¼°æ¨¡å‹
            metrics = self.evaluate_model(X_test, y_test)
            
            # 5. ä¿å­˜æ¨¡å‹
            model_paths = self.config.get_model_paths()
            self.save_model(model_paths['geographic_model'], model_paths['feature_scaler'])
            
            # 6. è¿”å›ç»“æœ
            result = {
                'model_type': 'LSTM',
                'target': 'geographic',
                'metrics': metrics,
                'model_path': model_paths['geographic_model'],
                'scaler_path': model_paths['feature_scaler']
            }
            
            self.logger.info("ğŸ‰ Geographicæ¨¡å‹è®­ç»ƒæµç¨‹å®Œæˆ!")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Geographicæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            raise 