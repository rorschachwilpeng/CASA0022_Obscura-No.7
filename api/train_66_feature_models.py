#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
66ç‰¹å¾æ¨¡å‹è®­ç»ƒè„šæœ¬
æ”¯æŒLSTMã€Random Forestã€Deep 1D-CNNä¸‰ç§æ¶æ„
"""

import sys
import os
import numpy as np
import pandas as pd
from datetime import datetime
import joblib
import json
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

# MLç›¸å…³åº“
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

# æ·±åº¦å­¦ä¹ ç›¸å…³åº“
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
    TF_AVAILABLE = True
    print("âœ… TensorFlowå¯ç”¨")
except ImportError:
    TF_AVAILABLE = False
    print("âŒ TensorFlowä¸å¯ç”¨ï¼Œå°†è·³è¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹")

from utils.simplified_feature_engineer import get_simplified_feature_engineer

class ModelTrainer:
    """66ç‰¹å¾æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, output_dir: str = "trained_models_66"):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        self.output_dir = output_dir
        self.feature_engineer = get_simplified_feature_engineer()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # æ¨¡å‹é…ç½®
        self.models_config = {
            'lstm': {
                'name': 'LSTM',
                'description': 'Long Short-Term Memory Neural Network',
                'requires_tf': True
            },
            'rf': {
                'name': 'Random Forest',
                'description': 'Random Forest Regressor',
                'requires_tf': False
            },
            'cnn1d': {
                'name': 'Deep 1D-CNN',
                'description': '1D Convolutional Neural Network',
                'requires_tf': True
            }
        }
        
        print(f"ModelTraineråˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºç›®å½•: {self.output_dir}")
    
    def generate_synthetic_training_data(self, n_samples: int = 1000) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ® (ç”¨äºæ¼”ç¤ºï¼Œå®é™…åº”ä½¿ç”¨çœŸå®å†å²æ•°æ®)
        
        Returns:
            X: ç‰¹å¾æ•°æ® (n_samples, 66)
            y_climate: Climate Scoreæ ‡ç­¾ (n_samples,)
            y_geographic: Geographic Scoreæ ‡ç­¾ (n_samples,)
        """
        print(f"ğŸ² ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®: {n_samples} æ ·æœ¬")
        
        # åŸå¸‚åæ ‡èŒƒå›´ (è‹±å›½)
        lat_range = (50.0, 60.0)
        lon_range = (-6.0, 2.0)
        
        # ç”Ÿæˆéšæœºåæ ‡å’Œæœˆä»½
        np.random.seed(42)  # å›ºå®šç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§
        latitudes = np.random.uniform(lat_range[0], lat_range[1], n_samples)
        longitudes = np.random.uniform(lon_range[0], lon_range[1], n_samples)
        months = np.random.randint(1, 13, n_samples)
        
        X = []
        y_climate = []
        y_geographic = []
        
        for i, (lat, lon, month) in enumerate(zip(latitudes, longitudes, months)):
            if i % 100 == 0:
                print(f"   ç”Ÿæˆæ ·æœ¬ {i+1}/{n_samples}")
            
            try:
                # ç”Ÿæˆ66ç‰¹å¾
                features = self.feature_engineer.prepare_features_for_prediction(lat, lon, month, 66)
                
                # ç”Ÿæˆåˆæˆæ ‡ç­¾ (åŸºäºç‰¹å¾çš„ç®€å•å‡½æ•°)
                # Climate Score: åŸºäºæ¸©åº¦ã€æ¹¿åº¦ã€é™æ°´ç­‰æ°”è±¡å› ç´ 
                climate_features = features[:44]  # å‰44ä¸ªæ˜¯æ»åç‰¹å¾
                climate_score = np.tanh(np.mean(climate_features[:11]) / 100) * 2  # æ ‡å‡†åŒ–åˆ°[-2, 2]
                
                # Geographic Score: åŸºäºåœ°ç†ä½ç½®å’ŒåœŸå£¤å› ç´ 
                geo_features = features[44:]  # å22ä¸ªæ˜¯å˜åŒ–ç‡ç‰¹å¾
                geographic_score = np.tanh(np.mean(geo_features) * 0.5) * 1.5  # æ ‡å‡†åŒ–åˆ°[-1.5, 1.5]
                
                X.append(features)
                y_climate.append(climate_score)
                y_geographic.append(geographic_score)
                
            except Exception as e:
                print(f"   âš ï¸ è·³è¿‡æ ·æœ¬ {i}: {e}")
                continue
        
        X = np.array(X)
        y_climate = np.array(y_climate)
        y_geographic = np.array(y_geographic)
        
        print(f"âœ… è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ:")
        print(f"   ç‰¹å¾å½¢çŠ¶: {X.shape}")
        print(f"   Climateæ ‡ç­¾èŒƒå›´: [{y_climate.min():.3f}, {y_climate.max():.3f}]")
        print(f"   Geographicæ ‡ç­¾èŒƒå›´: [{y_geographic.min():.3f}, {y_geographic.max():.3f}]")
        
        return X, y_climate, y_geographic
    
    def train_random_forest(self, X_train: np.ndarray, y_train: np.ndarray, 
                           target_name: str) -> Tuple[Any, Dict]:
        """è®­ç»ƒRandom Forestæ¨¡å‹"""
        print(f"ğŸŒ² è®­ç»ƒRandom Forestæ¨¡å‹ - {target_name}")
        
        # RFé…ç½®
        rf_config = {
            'n_estimators': 100,
            'max_depth': 20,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'random_state': 42,
            'n_jobs': -1
        }
        
        # è®­ç»ƒæ¨¡å‹
        model = RandomForestRegressor(**rf_config)
        model.fit(X_train, y_train)
        
        # ç‰¹å¾é‡è¦æ€§
        feature_names = self.feature_engineer.get_feature_names()
        feature_importance = dict(zip(feature_names, model.feature_importances_))
        
        # è¿”å›æ¨¡å‹å’Œå…ƒæ•°æ®
        metadata = {
            'model_type': 'RandomForest',
            'config': rf_config,
            'feature_importance': feature_importance,
            'n_features': X_train.shape[1],
            'n_samples': X_train.shape[0]
        }
        
        print(f"   âœ… Random Forestè®­ç»ƒå®Œæˆ")
        return model, metadata
    
    def train_lstm(self, X_train: np.ndarray, y_train: np.ndarray,
                   X_val: np.ndarray, y_val: np.ndarray, target_name: str) -> Tuple[Any, Dict]:
        """è®­ç»ƒLSTMæ¨¡å‹"""
        print(f"ğŸ§  è®­ç»ƒLSTMæ¨¡å‹ - {target_name}")
        
        if not TF_AVAILABLE:
            raise RuntimeError("TensorFlowä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒLSTMæ¨¡å‹")
        
        # é‡å¡‘æ•°æ®ä¸ºLSTMæ ¼å¼ (samples, timesteps, features)
        # å°†66ä¸ªç‰¹å¾é‡ç»„ä¸ºæ—¶é—´åºåˆ—ï¼š4ä¸ªæ—¶é—´æ­¥ Ã— 16.5ä¸ªç‰¹å¾/æ­¥
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ (samples, 66, 1) æ ¼å¼
        X_train_lstm = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
        X_val_lstm = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)
        
        # LSTMæ¶æ„
        model = Sequential([
            LSTM(64, return_sequences=True, input_shape=(66, 1)),
            Dropout(0.2),
            LSTM(32, return_sequences=False),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='linear')
        ])
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        # å›è°ƒå‡½æ•°
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)
        ]
        
        # è®­ç»ƒæ¨¡å‹
        print(f"   è®­ç»ƒLSTM...")
        history = model.fit(
            X_train_lstm, y_train,
            validation_data=(X_val_lstm, y_val),
            epochs=50,
            batch_size=32,
            callbacks=callbacks,
            verbose=0
        )
        
        # å…ƒæ•°æ®
        metadata = {
            'model_type': 'LSTM',
            'architecture': {
                'layers': ['LSTM(64)', 'Dropout(0.2)', 'LSTM(32)', 'Dropout(0.2)', 'Dense(16)', 'Dense(1)'],
                'optimizer': 'Adam(0.001)',
                'loss': 'mse'
            },
            'training_history': {
                'final_loss': float(history.history['loss'][-1]),
                'final_val_loss': float(history.history['val_loss'][-1]),
                'epochs_trained': len(history.history['loss'])
            },
            'n_features': X_train.shape[1],
            'n_samples': X_train.shape[0]
        }
        
        print(f"   âœ… LSTMè®­ç»ƒå®Œæˆï¼Œè®­ç»ƒäº†{metadata['training_history']['epochs_trained']}è½®")
        return model, metadata
    
    def train_cnn1d(self, X_train: np.ndarray, y_train: np.ndarray,
                    X_val: np.ndarray, y_val: np.ndarray, target_name: str) -> Tuple[Any, Dict]:
        """è®­ç»ƒ1D CNNæ¨¡å‹"""
        print(f"ğŸ” è®­ç»ƒDeep 1D-CNNæ¨¡å‹ - {target_name}")
        
        if not TF_AVAILABLE:
            raise RuntimeError("TensorFlowä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒCNNæ¨¡å‹")
        
        # é‡å¡‘æ•°æ®ä¸ºCNNæ ¼å¼ (samples, features, channels)
        X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
        X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)
        
        # 1D CNNæ¶æ„
        model = Sequential([
            Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(66, 1)),
            MaxPooling1D(pool_size=2),
            Conv1D(filters=32, kernel_size=3, activation='relu'),
            MaxPooling1D(pool_size=2),
            Conv1D(filters=16, kernel_size=3, activation='relu'),
            Flatten(),
            Dense(50, activation='relu'),
            Dropout(0.3),
            Dense(25, activation='relu'),
            Dense(1, activation='linear')
        ])
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        # å›è°ƒå‡½æ•°
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)
        ]
        
        # è®­ç»ƒæ¨¡å‹
        print(f"   è®­ç»ƒ1D CNN...")
        history = model.fit(
            X_train_cnn, y_train,
            validation_data=(X_val_cnn, y_val),
            epochs=50,
            batch_size=32,
            callbacks=callbacks,
            verbose=0
        )
        
        # å…ƒæ•°æ®
        metadata = {
            'model_type': '1D-CNN',
            'architecture': {
                'layers': ['Conv1D(64,3)', 'MaxPool1D(2)', 'Conv1D(32,3)', 'MaxPool1D(2)', 
                          'Conv1D(16,3)', 'Flatten', 'Dense(50)', 'Dropout(0.3)', 'Dense(25)', 'Dense(1)'],
                'optimizer': 'Adam(0.001)',
                'loss': 'mse'
            },
            'training_history': {
                'final_loss': float(history.history['loss'][-1]),
                'final_val_loss': float(history.history['val_loss'][-1]),
                'epochs_trained': len(history.history['loss'])
            },
            'n_features': X_train.shape[1],
            'n_samples': X_train.shape[0]
        }
        
        print(f"   âœ… 1D CNNè®­ç»ƒå®Œæˆï¼Œè®­ç»ƒäº†{metadata['training_history']['epochs_trained']}è½®")
        return model, metadata
    
    def evaluate_model(self, model, X_test: np.ndarray, y_test: np.ndarray,
                      model_type: str, target_name: str) -> Dict:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print(f"ğŸ“Š è¯„ä¼°{model_type}æ¨¡å‹æ€§èƒ½ - {target_name}")
        
        # é¢„æµ‹
        if model_type in ['LSTM', '1D-CNN']:
            if model_type == 'LSTM':
                X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
            else:  # CNN
                X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
            y_pred = model.predict(X_test_reshaped, verbose=0).flatten()
        else:  # RF
            y_pred = model.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # é¢å¤–æŒ‡æ ‡
        mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100  # é¿å…é™¤é›¶
        
        metrics = {
            'MSE': float(mse),
            'RMSE': float(rmse),
            'MAE': float(mae),
            'R2': float(r2),
            'MAPE': float(mape),
            'predictions_range': {
                'min': float(y_pred.min()),
                'max': float(y_pred.max()),
                'mean': float(y_pred.mean()),
                'std': float(y_pred.std())
            },
            'true_range': {
                'min': float(y_test.min()),
                'max': float(y_test.max()),
                'mean': float(y_test.mean()),
                'std': float(y_test.std())
            }
        }
        
        print(f"   RMSE: {rmse:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}")
        return metrics
    
    def save_model(self, model, metadata: Dict, model_type: str, target_name: str):
        """ä¿å­˜æ¨¡å‹å’Œå…ƒæ•°æ®"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜æ¨¡å‹
        if model_type in ['LSTM', '1D-CNN']:
            model_path = os.path.join(self.output_dir, f"{model_type}_{target_name}_{timestamp}.h5")
            model.save(model_path)
        else:  # RF
            model_path = os.path.join(self.output_dir, f"{model_type}_{target_name}_{timestamp}.joblib")
            joblib.dump(model, model_path)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata_path = os.path.join(self.output_dir, f"{model_type}_{target_name}_{timestamp}_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"   ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
        return model_path, metadata_path

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¼€å§‹66ç‰¹å¾æ¨¡å‹è®­ç»ƒ")
    print("=" * 80)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = ModelTrainer()
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    print(f"\n" + "=" * 60)
    print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®")
    print("=" * 60)
    
    X, y_climate, y_geographic = trainer.generate_synthetic_training_data(n_samples=500)
    
    # æ•°æ®åˆ†å‰²
    X_train, X_test, y_climate_train, y_climate_test = train_test_split(
        X, y_climate, test_size=0.2, random_state=42)
    
    _, _, y_geo_train, y_geo_test = train_test_split(
        X, y_geographic, test_size=0.2, random_state=42)
    
    # è¿›ä¸€æ­¥åˆ†å‰²è®­ç»ƒé›†ä»¥è·å¾—éªŒè¯é›†
    X_train, X_val, y_climate_train, y_climate_val = train_test_split(
        X_train, y_climate_train, test_size=0.2, random_state=42)
    
    _, _, y_geo_train, y_geo_val = train_test_split(
        X_train, y_geo_train, test_size=0.2, random_state=42)
    
    print(f"è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬") 
    print(f"æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    
    # æ ‡å‡†åŒ–ç‰¹å¾ (ä»…å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # ä¿å­˜scaler
    scaler_path = os.path.join(trainer.output_dir, "feature_scaler.joblib")
    joblib.dump(scaler, scaler_path)
    print(f"ç‰¹å¾æ ‡å‡†åŒ–å™¨å·²ä¿å­˜: {scaler_path}")
    
    # è®­ç»ƒç»“æœå­˜å‚¨
    training_results = {}
    
    # è¦è®­ç»ƒçš„ç›®æ ‡
    targets = {
        'climate': (y_climate_train, y_climate_val, y_climate_test),
        'geographic': (y_geo_train, y_geo_val, y_geo_test)
    }
    
    for target_name, (y_train, y_val, y_test) in targets.items():
        print(f"\n" + "=" * 60)
        print(f"ğŸ¯ è®­ç»ƒ{target_name.upper()}æ¨¡å‹")
        print("=" * 60)
        
        target_results = {}
        
        # 1. è®­ç»ƒRandom Forest
        print(f"\n1ï¸âƒ£ Random Forest - {target_name}")
        print("-" * 40)
        try:
            rf_model, rf_metadata = trainer.train_random_forest(X_train, y_train, target_name)
            rf_metrics = trainer.evaluate_model(rf_model, X_test, y_test, 'RandomForest', target_name)
            rf_model_path, rf_meta_path = trainer.save_model(rf_model, {**rf_metadata, 'metrics': rf_metrics}, 
                                                           'RandomForest', target_name)
            
            target_results['RandomForest'] = {
                'model_path': rf_model_path,
                'metadata_path': rf_meta_path,
                'metrics': rf_metrics,
                'metadata': rf_metadata
            }
            print(f"âœ… Random Forestå®Œæˆ")
            
        except Exception as e:
            print(f"âŒ Random Forestå¤±è´¥: {e}")
            target_results['RandomForest'] = {'error': str(e)}
        
        # 2. è®­ç»ƒLSTM
        print(f"\n2ï¸âƒ£ LSTM - {target_name}")
        print("-" * 40)
        try:
            if TF_AVAILABLE:
                lstm_model, lstm_metadata = trainer.train_lstm(X_train_scaled, y_train, 
                                                             X_val_scaled, y_val, target_name)
                lstm_metrics = trainer.evaluate_model(lstm_model, X_test_scaled, y_test, 'LSTM', target_name)
                lstm_model_path, lstm_meta_path = trainer.save_model(lstm_model, 
                                                                   {**lstm_metadata, 'metrics': lstm_metrics}, 
                                                                   'LSTM', target_name)
                
                target_results['LSTM'] = {
                    'model_path': lstm_model_path,
                    'metadata_path': lstm_meta_path,
                    'metrics': lstm_metrics,
                    'metadata': lstm_metadata
                }
                print(f"âœ… LSTMå®Œæˆ")
            else:
                print(f"âš ï¸ TensorFlowä¸å¯ç”¨ï¼Œè·³è¿‡LSTM")
                target_results['LSTM'] = {'error': 'TensorFlow not available'}
                
        except Exception as e:
            print(f"âŒ LSTMå¤±è´¥: {e}")
            target_results['LSTM'] = {'error': str(e)}
        
        # 3. è®­ç»ƒ1D CNN
        print(f"\n3ï¸âƒ£ Deep 1D-CNN - {target_name}")
        print("-" * 40)
        try:
            if TF_AVAILABLE:
                cnn_model, cnn_metadata = trainer.train_cnn1d(X_train_scaled, y_train,
                                                            X_val_scaled, y_val, target_name)
                cnn_metrics = trainer.evaluate_model(cnn_model, X_test_scaled, y_test, '1D-CNN', target_name)
                cnn_model_path, cnn_meta_path = trainer.save_model(cnn_model,
                                                                 {**cnn_metadata, 'metrics': cnn_metrics},
                                                                 '1D-CNN', target_name)
                
                target_results['1D-CNN'] = {
                    'model_path': cnn_model_path,
                    'metadata_path': cnn_meta_path,
                    'metrics': cnn_metrics,
                    'metadata': cnn_metadata
                }
                print(f"âœ… 1D-CNNå®Œæˆ")
            else:
                print(f"âš ï¸ TensorFlowä¸å¯ç”¨ï¼Œè·³è¿‡1D-CNN")
                target_results['1D-CNN'] = {'error': 'TensorFlow not available'}
                
        except Exception as e:
            print(f"âŒ 1D-CNNå¤±è´¥: {e}")
            target_results['1D-CNN'] = {'error': str(e)}
        
        training_results[target_name] = target_results
    
    # ä¿å­˜å®Œæ•´çš„è®­ç»ƒç»“æœ
    results_path = os.path.join(trainer.output_dir, f"training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(training_results, f, indent=2, ensure_ascii=False)
    
    print(f"\n" + "=" * 80)
    print("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print("=" * 80)
    print(f"â° å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“„ å®Œæ•´ç»“æœå·²ä¿å­˜: {results_path}")
    
    return training_results

if __name__ == "__main__":
    results = main() 