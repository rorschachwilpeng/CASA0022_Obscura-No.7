#!/usr/bin/env python3
"""
å®Œæ•´ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•
æ¨¡æ‹Ÿï¼šæ ‘è“æ´¾è¾“å…¥ â†’ åæ ‡è®¡ç®— â†’ ç½‘ç«™ML API â†’ AIå›¾åƒç”Ÿæˆ â†’ å±•ç¤º
"""

import requests
import json
import sys
import os
import time
import math
from datetime import datetime, timedelta

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.insert(0, 'raspberry_pi_deployment/core')
sys.path.insert(0, 'ML_Models')

def simulate_hardware_input():
    """æ¨¡æ‹Ÿç¡¬ä»¶è¾“å…¥"""
    print("ğŸ® æ¨¡æ‹Ÿç¡¬ä»¶è¾“å…¥ï¼ˆæ ‘è“æ´¾ï¼‰...")
    
    # æ¨¡æ‹Ÿç”¨æˆ·é€‰æ‹©
    hardware_input = {
        'distance_km': 50.0,        # è·ç¦» 50å…¬é‡Œ
        'direction_degrees': 45.0,   # ä¸œåŒ—æ–¹å‘ 45åº¦
        'time_offset_years': 2       # é¢„æµ‹ 2å¹´å
    }
    
    print(f"   è·ç¦»: {hardware_input['distance_km']} km")
    print(f"   æ–¹å‘: {hardware_input['direction_degrees']}Â° (ä¸œåŒ—)")
    print(f"   æ—¶é—´åç§»: {hardware_input['time_offset_years']} å¹´å")
    
    return hardware_input

def calculate_target_coordinates(hardware_input, base_lat=51.5074, base_lon=-0.1278):
    """è®¡ç®—ç›®æ ‡åæ ‡"""
    print("\nğŸ“ è®¡ç®—ç›®æ ‡åæ ‡...")
    
    distance_m = hardware_input['distance_km'] * 1000
    direction_rad = math.radians(hardware_input['direction_degrees'])
    
    # åœ°çƒåŠå¾„ (ç±³)
    R = 6371000
    
    # è®¡ç®—æ–°åæ ‡
    lat1 = math.radians(base_lat)
    lon1 = math.radians(base_lon)
    
    lat2 = math.asin(
        math.sin(lat1) * math.cos(distance_m / R) +
        math.cos(lat1) * math.sin(distance_m / R) * math.cos(direction_rad)
    )
    
    lon2 = lon1 + math.atan2(
        math.sin(direction_rad) * math.sin(distance_m / R) * math.cos(lat1),
        math.cos(distance_m / R) - math.sin(lat1) * math.sin(lat2)
    )
    
    target_coords = {
        'latitude': math.degrees(lat2),
        'longitude': math.degrees(lon2),
        'distance_km': hardware_input['distance_km'],
        'direction_degrees': hardware_input['direction_degrees']
    }
    
    print(f"   åŸºç¡€ä½ç½®: {base_lat:.4f}, {base_lon:.4f} (ä¼¦æ•¦)")
    print(f"   ç›®æ ‡ä½ç½®: {target_coords['latitude']:.4f}, {target_coords['longitude']:.4f}")
    
    return target_coords

def call_ml_prediction_api(coordinates, time_offset_years, api_base="http://localhost:5000"):
    """è°ƒç”¨ç½‘ç«™MLé¢„æµ‹APIï¼ˆç›´æ¥ä½¿ç”¨Flaskåº”ç”¨ï¼‰"""
    print("\nğŸ¤– è°ƒç”¨ç½‘ç«™MLé¢„æµ‹API...")
    
    # æ„å»ºAPIè¯·æ±‚
    prediction_request = {
        'latitude': coordinates['latitude'],
        'longitude': coordinates['longitude'],
        'month': datetime.now().month,
        'future_years': time_offset_years
    }
    
    try:
        # ç›´æ¥ä½¿ç”¨Flaskåº”ç”¨æµ‹è¯•å®¢æˆ·ç«¯
        sys.path.insert(0, 'api')
        from app import create_app
        
        print(f"   è¯·æ±‚æ•°æ®: {prediction_request}")
        
        # åˆ›å»ºåº”ç”¨å®ä¾‹
        app = create_app()
        
        # ä½¿ç”¨æµ‹è¯•å®¢æˆ·ç«¯
        with app.test_client() as client:
            response = client.post('/api/v1/ml/predict', 
                                   json=prediction_request,
                                   content_type='application/json')
            
            if response.status_code == 200:
                prediction_data = response.get_json()
                print("   âœ… APIè°ƒç”¨æˆåŠŸ!")
                
                prediction = prediction_data.get('prediction', {})
                location_info = prediction_data.get('location_info', {})
                
                print(f"   æœ€è¿‘åŸå¸‚: {location_info.get('closest_city', 'Unknown')}")
                print(f"   é¢„æµ‹æ¸©åº¦: {prediction.get('temperature', 'N/A'):.2f}Â°C")
                print(f"   é¢„æµ‹æ¹¿åº¦: {prediction.get('humidity', 'N/A'):.1f}%")
                print(f"   é¢„æµ‹å‹åŠ›: {prediction.get('pressure', 'N/A'):.1f} hPa")
                print(f"   æ¨¡å‹ç‰ˆæœ¬: {prediction.get('model_version', 'N/A')}")
                print(f"   ç½®ä¿¡åº¦: {prediction.get('prediction_confidence', 'N/A')}")
                print(f"   æ¨¡å‹ç±»å‹: {prediction.get('model_type', 'N/A')}")
                
                return prediction_data
                
            else:
                print(f"   âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                print(f"   é”™è¯¯å“åº”: {response.get_data(as_text=True)}")
                return None
                
    except Exception as e:
        print(f"   âŒ APIè¯·æ±‚å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_ai_prompt(prediction_data, coordinates):
    """åŸºäºé¢„æµ‹æ•°æ®ç”ŸæˆAIå›¾åƒæç¤ºè¯"""
    print("\nğŸ¨ ç”ŸæˆAIå›¾åƒæç¤ºè¯...")
    
    prediction = prediction_data.get('prediction', {})
    location_info = prediction_data.get('location_info', {})
    
    temperature = prediction.get('temperature', 15)
    humidity = prediction.get('humidity', 60)
    closest_city = location_info.get('closest_city', 'Unknown')
    prediction_type = location_info.get('prediction_type', 'current')
    
    # åŸºäºæ¸©åº¦ç¡®å®šå­£èŠ‚æè¿°
    if temperature < 5:
        season_desc = "cold winter landscape with frost and snow"
    elif temperature < 15:
        season_desc = "cool autumn or spring scene with moderate weather"
    elif temperature < 25:
        season_desc = "pleasant temperate climate with mild conditions"
    else:
        season_desc = "warm summer environment with lush vegetation"
    
    # åŸºäºæ¹¿åº¦ç¡®å®šå¤§æ°”æè¿°
    if humidity < 40:
        humidity_desc = "clear, dry atmosphere"
    elif humidity < 70:
        humidity_desc = "comfortable humidity with slight haze"
    else:
        humidity_desc = "moist, humid air with possible mist"
    
    # æ„å»ºæç¤ºè¯
    base_prompt = f"Steampunk environmental art depicting {season_desc} near {closest_city}"
    
    if prediction_type == "future":
        base_prompt += f", showing climate change effects in a future scenario"
    
    ai_prompt = f"{base_prompt} with {humidity_desc}, Victorian-era brass instruments measuring weather, copper pipes and steam, fantasy environmental monitoring station, detailed digital art"
    
    print(f"   AIæç¤ºè¯: {ai_prompt}")
    
    return {
        'prompt': ai_prompt,
        'temperature': temperature,
        'humidity': humidity,
        'season_description': season_desc,
        'location': closest_city,
        'prediction_type': prediction_type
    }

def simulate_image_generation(ai_prompt_data):
    """æ¨¡æ‹ŸAIå›¾åƒç”Ÿæˆ"""
    print("\nğŸ–¼ï¸ æ¨¡æ‹ŸAIå›¾åƒç”Ÿæˆ...")
    
    # æ¨¡æ‹Ÿå›¾åƒç”Ÿæˆè¿‡ç¨‹
    print(f"   ä½¿ç”¨æç¤ºè¯: {ai_prompt_data['prompt'][:100]}...")
    print(f"   ä¸»é¢˜: {ai_prompt_data['season_description']}")
    print(f"   ä½ç½®: {ai_prompt_data['location']}")
    
    # æ¨¡æ‹Ÿç”Ÿæˆç»“æœ
    image_info = {
        'success': True,
        'image_url': f"https://example.com/generated/telescope_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
        'prompt_used': ai_prompt_data['prompt'],
        'generation_time': 15.3,
        'style': 'steampunk_environmental',
        'dimensions': '1024x1024'
    }
    
    print(f"   âœ… å›¾åƒç”ŸæˆæˆåŠŸ!")
    print(f"   å›¾åƒURL: {image_info['image_url']}")
    print(f"   ç”Ÿæˆæ—¶é—´: {image_info['generation_time']} ç§’")
    print(f"   å°ºå¯¸: {image_info['dimensions']}")
    
    return image_info

def create_workflow_summary(hardware_input, coordinates, prediction_data, ai_prompt_data, image_info):
    """åˆ›å»ºå·¥ä½œæµæ€»ç»“"""
    print("\nğŸ“Š åˆ›å»ºå·¥ä½œæµæ€»ç»“...")
    
    workflow_summary = {
        'workflow_id': f"test_workflow_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        'timestamp': datetime.now().isoformat(),
        'device_type': 'simulated_raspberry_pi',
        'status': 'completed',
        'steps': {
            '1_hardware_input': hardware_input,
            '2_coordinates': coordinates,
            '3_ml_prediction': prediction_data,
            '4_ai_prompt': ai_prompt_data,
            '5_image_generation': image_info
        },
        'summary': {
            'location': prediction_data.get('location_info', {}).get('closest_city', 'Unknown'),
            'predicted_temperature': prediction_data.get('prediction', {}).get('temperature'),
            'future_years': hardware_input.get('time_offset_years', 0),
            'image_generated': image_info.get('success', False),
            'total_processing_time': '45.2 seconds'
        }
    }
    
    # ä¿å­˜æ€»ç»“åˆ°æ–‡ä»¶
    output_file = f"workflow_outputs/workflow_summary_{workflow_summary['workflow_id']}.json"
    os.makedirs('workflow_outputs', exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(workflow_summary, f, indent=2, ensure_ascii=False)
    
    print(f"   å·¥ä½œæµæ€»ç»“å·²ä¿å­˜: {output_file}")
    
    return workflow_summary

def display_final_results(workflow_summary):
    """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
    print("\n" + "=" * 60)
    print("ğŸ¯ ç«¯åˆ°ç«¯å·¥ä½œæµå®Œæˆ!")
    print("=" * 60)
    
    summary = workflow_summary['summary']
    
    print(f"ğŸ†” å·¥ä½œæµID: {workflow_summary['workflow_id']}")
    print(f"ğŸ“ ç›®æ ‡ä½ç½®: {summary['location']}")
    print(f"ğŸŒ¡ï¸ é¢„æµ‹æ¸©åº¦: {summary['predicted_temperature']:.2f}Â°C")
    print(f"â³ æœªæ¥é¢„æµ‹: {summary['future_years']} å¹´å")
    print(f"ğŸ–¼ï¸ å›¾åƒç”Ÿæˆ: {'æˆåŠŸ' if summary['image_generated'] else 'å¤±è´¥'}")
    print(f"â±ï¸ æ€»å¤„ç†æ—¶é—´: {summary['total_processing_time']}")
    
    print("\nğŸ”— æ•°æ®æµé“¾è·¯:")
    print("   æ ‘è“æ´¾ç¡¬ä»¶è¾“å…¥ â†’ åæ ‡è®¡ç®— â†’ ç½‘ç«™ML API â†’ AIæç¤ºè¯ç”Ÿæˆ â†’ å›¾åƒç”Ÿæˆ")
    
    steps = workflow_summary['steps']
    coords = steps['2_coordinates']
    print(f"\nğŸ“ åæ ‡è½¬æ¢:")
    print(f"   è·ç¦»: {coords['distance_km']} km")
    print(f"   æ–¹å‘: {coords['direction_degrees']}Â°")
    print(f"   ç»“æœ: ({coords['latitude']:.4f}, {coords['longitude']:.4f})")
    
    prediction = steps['3_ml_prediction']['prediction']
    print(f"\nğŸ¤– MLé¢„æµ‹:")
    print(f"   æ¸©åº¦: {prediction['temperature']:.2f}Â°C")
    print(f"   æ¹¿åº¦: {prediction['humidity']:.1f}%")
    print(f"   å‹åŠ›: {prediction['pressure']:.1f} hPa")
    
    print(f"\nğŸ¨ AIç”Ÿæˆ:")
    prompt = steps['4_ai_prompt']['prompt']
    print(f"   æç¤ºè¯: {prompt[:80]}...")
    print(f"   é£æ ¼: è’¸æ±½æœ‹å…‹ç¯å¢ƒè‰ºæœ¯")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å®Œæ•´ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•")
    print("æ¨¡æ‹Ÿï¼šæ ‘è“æ´¾ â†’ åæ ‡è®¡ç®— â†’ ç½‘ç«™ML API â†’ AIå›¾åƒç”Ÿæˆ")
    print("=" * 60)
    
    try:
        # æ­¥éª¤1: æ¨¡æ‹Ÿç¡¬ä»¶è¾“å…¥
        hardware_input = simulate_hardware_input()
        
        # æ­¥éª¤2: è®¡ç®—ç›®æ ‡åæ ‡
        coordinates = calculate_target_coordinates(hardware_input)
        
        # æ­¥éª¤3: è°ƒç”¨MLé¢„æµ‹API
        prediction_data = call_ml_prediction_api(
            coordinates, 
            hardware_input['time_offset_years']
        )
        
        if not prediction_data:
            print("âŒ MLé¢„æµ‹å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å·¥ä½œæµ")
            return
        
        # æ­¥éª¤4: ç”ŸæˆAIæç¤ºè¯
        ai_prompt_data = generate_ai_prompt(prediction_data, coordinates)
        
        # æ­¥éª¤5: æ¨¡æ‹Ÿå›¾åƒç”Ÿæˆ
        image_info = simulate_image_generation(ai_prompt_data)
        
        # æ­¥éª¤6: åˆ›å»ºå·¥ä½œæµæ€»ç»“
        workflow_summary = create_workflow_summary(
            hardware_input, coordinates, prediction_data, 
            ai_prompt_data, image_info
        )
        
        # æ­¥éª¤7: æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        display_final_results(workflow_summary)
        
        print("\nâœ… å®Œæ•´å·¥ä½œæµæµ‹è¯•æˆåŠŸ!")
        
    except Exception as e:
        print(f"\nâŒ å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 